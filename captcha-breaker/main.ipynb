{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torchvision import models\n",
    "import torch.nn as nn\n",
    "import pytesseract\n",
    "# from fastai.vision import Path\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import cv2\n",
    "from imutils import contours\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "# ALPHABET = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "ALL_CHAR_SET = NUMBER\n",
    "ALL_CHAR_SET_LEN = len(ALL_CHAR_SET)\n",
    "MAX_CAPTCHA = 5\n",
    "\n",
    "def encode(a):\n",
    "    onehot = [0]*ALL_CHAR_SET_LEN\n",
    "    idx = ALL_CHAR_SET.index(a)\n",
    "    onehot[idx] += 1\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx].img\n",
    "        img = Image.open(img_path)\n",
    "        img = img.convert('L')\n",
    "        label = self.df.iloc[idx].label\n",
    "        # label = Path(self.path/img_path).name[:-4]\n",
    "        label_oh = []\n",
    "        for i in label:\n",
    "            label_oh += encode(i)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, np.array(label_oh), label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3753, 2) (939, 2)\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "all_files = glob(os.path.join(\"..\", \"captcha\", \"fix\", \"captcha-*.png\"))\n",
    "df = pd.DataFrame({'img': all_files})\n",
    "df[\"label\"] = df.img.apply(lambda x: os.path.basename(x).split(\"-\")[1].split(\".\")[0].split(\"-\")[0])\n",
    "df.head()\n",
    "train_df, test_df = df.iloc[:int(df.shape[0]*0.8)], df.iloc[int(df.shape[0]*0.8):]\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import cpu_count, Process, Lock, Semaphore, Pool\n",
    "\n",
    "box_df = pd.DataFrame(columns=[\n",
    "                      \"img\", \"label\", \"label\", \"index\", \"x1\", \"x2\", \"y1\", \"y2\"])\n",
    "\n",
    "lock = Lock()\n",
    "semaphore = Semaphore(cpu_count()-1)\n",
    "# thread_progress = tqdm(total=df.shape[0])\n",
    "\n",
    "\n",
    "def get_to_box(row):\n",
    "\n",
    "    series_list = []\n",
    "    original_img = cv2.imread(row.img)  # Load the upsampled image\n",
    "    img = cv2.cvtColor(original_img, cv2.COLOR_BGR2HSV)\n",
    "    msk = cv2.inRange(img, np.array([50, 50, 50]), np.array([179, 255, 255]))\n",
    "    krn = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 3))\n",
    "    dlt = cv2.dilate(msk, krn, iterations=1)\n",
    "    thr = 255 - cv2.bitwise_and(dlt, msk)\n",
    "\n",
    "    # txt = pytesseract.image_to_string(\n",
    "    #     thr, config='-c  tessedit_char_whitelist=0123456789 --psm 6')\n",
    "    # print([t for t in txt if t.isalnum()])\n",
    "    boxes = pytesseract.image_to_boxes(\n",
    "        thr, config='-c  tessedit_char_whitelist=0123456789 --psm 6')\n",
    "    # img = thr.copy()\n",
    "\n",
    "    txt = \"\".join([t[0] for t in boxes.splitlines()])\n",
    "    print(\"txt\", txt)\n",
    "    if len(txt) == len(row.label):\n",
    "\n",
    "        lock.acquire()\n",
    "        for index, box in enumerate(boxes.splitlines()):\n",
    "            box = box.split()\n",
    "            series = pd.Series({\n",
    "                \"img\": row.img,\n",
    "                \"box_label\": row.label[index],\n",
    "                \"label\": row.label,\n",
    "                \"index\": index,\n",
    "                \"x1\": img.shape[0] - int(box[4]),\n",
    "                \"x2\": img.shape[0] - int(box[2]),\n",
    "                \"y1\": int(box[1]),\n",
    "                \"y2\": int(box[3]),\n",
    "            })\n",
    "            series_list.append(series)\n",
    "        lock.release()\n",
    "    return series_list\n",
    "    # thread_progress.update(1)\n",
    "    # semaphore.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4692 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "txttxt  \n",
      "txt\n",
      " "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/4692 [00:01<1:29:16,  1.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "txt \n",
      "txt 42354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 5/4692 [00:01<18:30,  4.22it/s]  \n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "all_processes = []\n",
    "# for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
    "#     p = Process(target=get_to_box, args=(row,))\n",
    "#     all_processes.append(p)\n",
    "#     semaphore.acquire()\n",
    "#     p.start()\n",
    "\n",
    "# for p in all_processes:\n",
    "#     p.join()\n",
    "s_list = []\n",
    "from concurrent.futures import ProcessPoolExecutor, wait, as_completed\n",
    "# for index, row in tqdm(df.iterrows():\n",
    "with ProcessPoolExecutor(max_workers=cpu_count()-1) as executor:\n",
    "    with tqdm(total=df.shape[0]) as p_bar:\n",
    "        futures_list = []\n",
    "        for index, row in df.iterrows():\n",
    "            future = executor.submit(get_to_box, row)\n",
    "            future.add_done_callback(lambda p: p_bar.update())\n",
    "            futures_list.append(future)\n",
    "        \n",
    "        for future in futures_list:\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                s_list = s_list + result\n",
    "\n",
    "\n",
    "\n",
    "b = pd.DataFrame(s_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img</th>\n",
       "      <th>box_label</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y1</th>\n",
       "      <th>y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../captcha/fix/captcha-42851.png</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../captcha/fix/captcha-42851.png</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>40</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../captcha/fix/captcha-42851.png</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>42</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../captcha/fix/captcha-42851.png</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../captcha/fix/captcha-42851.png</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>40</td>\n",
       "      <td>91</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                img box_label  x1  x2  y1   y2\n",
       "0  ../captcha/fix/captcha-42851.png         4  10  42  13   33\n",
       "1  ../captcha/fix/captcha-42851.png         2  11  40  33   54\n",
       "2  ../captcha/fix/captcha-42851.png         8  10  42  45   75\n",
       "3  ../captcha/fix/captcha-42851.png         5  11  41  57   91\n",
       "4  ../captcha/fix/captcha-42851.png         1  12  40  91  107"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.write_csv(\"box_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize([224, 224]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "train_ds = Mydataset(train_df, transform=transform)\n",
    "test_ds = Mydataset(test_df, transform=transform)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, num_workers=10, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=32, num_workers=10, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amir/.pyenv/versions/3.11.1/envs/automate_news/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/amir/.pyenv/versions/3.11.1/envs/automate_news/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet18(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "model.fc = nn.Linear(in_features=512, out_features=ALL_CHAR_SET_LEN*MAX_CAPTCHA, bias=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.MultiLabelSoftMarginLoss()\n",
    "optm = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eopch: 1 step: 1 loss: 0.7424418330192566\n",
      "eopch: 1 step: 2 loss: 0.5587933659553528\n",
      "eopch: 1 step: 3 loss: 0.4174691438674927\n",
      "eopch: 1 step: 4 loss: 0.35221850872039795\n",
      "eopch: 1 step: 5 loss: 0.3326190710067749\n",
      "eopch: 1 step: 6 loss: 0.3254120349884033\n",
      "eopch: 1 step: 7 loss: 0.3261052966117859\n",
      "eopch: 1 step: 8 loss: 0.331088125705719\n",
      "eopch: 1 step: 9 loss: 0.3397544324398041\n",
      "eopch: 1 step: 10 loss: 0.3322392702102661\n",
      "eopch: 1 step: 11 loss: 0.3339664041996002\n",
      "eopch: 1 step: 12 loss: 0.32724979519844055\n",
      "eopch: 1 step: 13 loss: 0.32407498359680176\n",
      "eopch: 1 step: 14 loss: 0.327959269285202\n",
      "eopch: 1 step: 15 loss: 0.3198370337486267\n",
      "eopch: 1 step: 16 loss: 0.3163624703884125\n",
      "eopch: 1 step: 17 loss: 0.31956231594085693\n",
      "eopch: 1 step: 18 loss: 0.3294880986213684\n",
      "eopch: 1 step: 19 loss: 0.31840401887893677\n",
      "eopch: 1 step: 20 loss: 0.31586265563964844\n",
      "eopch: 1 step: 21 loss: 0.32094481587409973\n",
      "eopch: 1 step: 22 loss: 0.3189174234867096\n",
      "eopch: 1 step: 23 loss: 0.3077778220176697\n",
      "eopch: 1 step: 24 loss: 0.3108813464641571\n",
      "eopch: 1 step: 25 loss: 0.30525222420692444\n",
      "eopch: 1 step: 26 loss: 0.31124988198280334\n",
      "eopch: 1 step: 27 loss: 0.31043246388435364\n",
      "eopch: 1 step: 28 loss: 0.3155517876148224\n",
      "eopch: 1 step: 29 loss: 0.30843284726142883\n",
      "eopch: 1 step: 30 loss: 0.30935966968536377\n",
      "eopch: 1 step: 31 loss: 0.29644906520843506\n",
      "eopch: 1 step: 32 loss: 0.29735267162323\n",
      "eopch: 1 step: 33 loss: 0.3021520972251892\n",
      "eopch: 1 step: 34 loss: 0.2955462634563446\n",
      "eopch: 1 step: 35 loss: 0.3048831820487976\n",
      "eopch: 1 step: 36 loss: 0.2960301637649536\n",
      "eopch: 1 step: 37 loss: 0.29989856481552124\n",
      "eopch: 1 step: 38 loss: 0.3049415946006775\n",
      "eopch: 1 step: 39 loss: 0.2920791506767273\n",
      "eopch: 1 step: 40 loss: 0.29263633489608765\n",
      "eopch: 1 step: 41 loss: 0.29617661237716675\n",
      "eopch: 1 step: 42 loss: 0.28113919496536255\n",
      "eopch: 1 step: 43 loss: 0.29500114917755127\n",
      "eopch: 1 step: 44 loss: 0.29284656047821045\n",
      "eopch: 1 step: 45 loss: 0.2856445014476776\n",
      "eopch: 1 step: 46 loss: 0.28986501693725586\n",
      "eopch: 1 step: 47 loss: 0.2886691689491272\n",
      "eopch: 1 step: 48 loss: 0.2859343886375427\n",
      "eopch: 1 step: 49 loss: 0.2836138904094696\n",
      "eopch: 1 step: 50 loss: 0.2807336449623108\n",
      "eopch: 1 step: 51 loss: 0.28645753860473633\n",
      "eopch: 1 step: 52 loss: 0.27954697608947754\n",
      "eopch: 1 step: 53 loss: 0.29114866256713867\n",
      "eopch: 1 step: 54 loss: 0.2735956609249115\n",
      "eopch: 1 step: 55 loss: 0.27210450172424316\n",
      "eopch: 1 step: 56 loss: 0.2697632908821106\n",
      "eopch: 1 step: 57 loss: 0.27836960554122925\n",
      "eopch: 1 step: 58 loss: 0.2762634754180908\n",
      "eopch: 1 step: 59 loss: 0.27187272906303406\n",
      "eopch: 1 step: 60 loss: 0.2652882933616638\n",
      "eopch: 1 step: 61 loss: 0.26262688636779785\n",
      "eopch: 1 step: 62 loss: 0.26681751012802124\n",
      "eopch: 1 step: 63 loss: 0.2621857523918152\n",
      "eopch: 1 step: 64 loss: 0.2684330642223358\n",
      "eopch: 1 step: 65 loss: 0.27150723338127136\n",
      "eopch: 1 step: 66 loss: 0.2720176875591278\n",
      "eopch: 1 step: 67 loss: 0.26395905017852783\n",
      "eopch: 1 step: 68 loss: 0.268588125705719\n",
      "eopch: 1 step: 69 loss: 0.2592164874076843\n",
      "eopch: 1 step: 70 loss: 0.26419609785079956\n",
      "eopch: 1 step: 71 loss: 0.26102229952812195\n",
      "eopch: 1 step: 72 loss: 0.25247037410736084\n",
      "eopch: 1 step: 73 loss: 0.2485530525445938\n",
      "eopch: 1 step: 74 loss: 0.2501969337463379\n",
      "eopch: 1 step: 75 loss: 0.23852726817131042\n",
      "eopch: 1 step: 76 loss: 0.25625181198120117\n",
      "eopch: 1 step: 77 loss: 0.2613776922225952\n",
      "eopch: 1 step: 78 loss: 0.2503310441970825\n",
      "eopch: 1 step: 79 loss: 0.2302122265100479\n",
      "eopch: 1 step: 80 loss: 0.24086728692054749\n",
      "eopch: 1 step: 81 loss: 0.23440439999103546\n",
      "eopch: 1 step: 82 loss: 0.2357766032218933\n",
      "eopch: 1 step: 83 loss: 0.22877109050750732\n",
      "eopch: 1 step: 84 loss: 0.2277202606201172\n",
      "eopch: 1 step: 85 loss: 0.23856386542320251\n",
      "eopch: 1 step: 86 loss: 0.23246726393699646\n",
      "eopch: 1 step: 87 loss: 0.2259850949048996\n",
      "eopch: 1 step: 88 loss: 0.22647905349731445\n",
      "eopch: 1 step: 89 loss: 0.23215609788894653\n",
      "eopch: 1 step: 90 loss: 0.23011399805545807\n",
      "eopch: 1 step: 91 loss: 0.21775378286838531\n",
      "eopch: 1 step: 92 loss: 0.22021260857582092\n",
      "eopch: 1 step: 93 loss: 0.21338073909282684\n",
      "eopch: 1 step: 94 loss: 0.22189868986606598\n",
      "eopch: 1 step: 95 loss: 0.19935879111289978\n",
      "eopch: 1 step: 96 loss: 0.21809646487236023\n",
      "eopch: 1 step: 97 loss: 0.200494647026062\n",
      "eopch: 1 step: 98 loss: 0.22147417068481445\n",
      "eopch: 1 step: 99 loss: 0.21201443672180176\n",
      "eopch: 1 step: 100 loss: 0.2030893862247467\n",
      "eopch: 1 step: 101 loss: 0.20522767305374146\n",
      "eopch: 1 step: 102 loss: 0.2044772505760193\n",
      "eopch: 1 step: 103 loss: 0.20014946162700653\n",
      "eopch: 1 step: 104 loss: 0.19683696329593658\n",
      "eopch: 1 step: 105 loss: 0.19201132655143738\n",
      "eopch: 1 step: 106 loss: 0.19951392710208893\n",
      "eopch: 1 step: 107 loss: 0.19079400599002838\n",
      "eopch: 1 step: 108 loss: 0.18297886848449707\n",
      "eopch: 1 step: 109 loss: 0.18416571617126465\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m loss \u001b[39m=\u001b[39m loss_func(pred, label_oh)\n\u001b[1;32m      8\u001b[0m optm\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> 9\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     10\u001b[0m optm\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39meopch:\u001b[39m\u001b[39m'\u001b[39m, epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstep:\u001b[39m\u001b[39m'\u001b[39m, step\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mloss:\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/automate_news/lib/python3.11/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.1/envs/automate_news/lib/python3.11/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(20):\n",
    "    for step, i in enumerate(train_dl):\n",
    "        img, label_oh, label = i\n",
    "        img = Variable(img).cuda()\n",
    "        label_oh = Variable(label_oh.float()).cuda()\n",
    "        pred = model(img)\n",
    "        loss = loss_func(pred, label_oh)\n",
    "        optm.zero_grad()\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "        print('eopch:', epoch+1, 'step:', step+1, 'loss:', loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=50, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct 24 wrong 784 acc 0.0297029702970297\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "for step, (img, label_oh, label) in enumerate(test_dl):\n",
    "    img = Variable(img).cuda()\n",
    "    preds = model(img)\n",
    "    for pred in preds:\n",
    "        # pred = preds[0]\n",
    "        c0 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[0:ALL_CHAR_SET_LEN])]\n",
    "        c1 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN:ALL_CHAR_SET_LEN*2])]\n",
    "        c2 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*2:ALL_CHAR_SET_LEN*3])]\n",
    "        c3 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*3:ALL_CHAR_SET_LEN*4])]\n",
    "        c4 = ALL_CHAR_SET[np.argmax(pred.squeeze().cpu().tolist()[ALL_CHAR_SET_LEN*4:ALL_CHAR_SET_LEN*5])]\n",
    "        c = '%s%s%s%s%s' % (c0, c1, c2, c3, c4)\n",
    "        if c == label[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            wrong += 1\n",
    "            # print('label:', label[0], 'pred:', c)\n",
    "\n",
    "\n",
    "print(\"correct\", correct, \"wrong\", wrong, \"acc\", correct/(correct+wrong))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
